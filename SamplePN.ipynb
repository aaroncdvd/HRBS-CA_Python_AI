{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SamplePN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0mF3QhAK8wiBisQhm6byT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaroncdvd/HRBS-CA_Python_AI/blob/main/SamplePN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGm1tIHaCDBT"
      },
      "source": [
        "# [>](https://developers.google.com/machine-learning/crash-course/fitter/graph) What is Learning!?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKm2GeLo80Bo"
      },
      "source": [
        "## Finding the Best Model by Minimizing the Errors\n",
        "\n",
        "**How does the average error look during training?**\n",
        "For instance, you are in a lake and must find the DEEPEST point, that's the global optimum. In other words, the 'best model'. \n",
        "\n",
        "You get into a BOAT and use an anchor and rope to measure the depth at different places. You compare each point with the LAST point you measured and make a graph. \n",
        "\n",
        "![PN](https://www.researchgate.net/profile/Md-Abu-Siddique-7/publication/330872299/figure/fig5/AS:722814940246018@1549343919385/Diagram-Showing-the-Cost-versus-Weight-Graph-In-Case-Of-Neural-Network-Gradient-Descent_Q640.jpg)\n",
        "\n",
        "HINT: It is important to MINIMIZE the number of times you measure since each time you stop and measure takes a LOT of time.\n",
        "\n",
        "**You need to decide how far you go between measurements and which direction you turn each time!**\n",
        "\n",
        "**Where is the model the BEST FIT in this map, the DEEPEST POINT?**\n",
        "\n",
        "[**What is the effect of the learning rate?**](https://developers.google.com/machine-learning/crash-course/fitter/graph)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9g4vWKaE589"
      },
      "source": [
        "## Class Example 'Error Lake'...\n",
        "![PN](https://cdn3.volusion.com/ckwhr.vgayx/v/vspfiles/photos/CRTR-D1S-3.jpg?v-cache=1483985255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NclFR0QE6aJ"
      },
      "source": [
        "## Real World Problem 'Error Lakes' look like this...\n",
        "![](https://cdn3.volusion.com/ckwhr.vgayx/v/vspfiles/photos/WIKE-D4L-2.jpg?v-cache=1483617506)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnXIkfDUx4Bn"
      },
      "source": [
        "# [>](https://analyticsindiamag.com/perceptron-is-the-only-neural-network-without-any-hidden-layer/) Sample Perceptron \n",
        "\n",
        "[Click This Link For Sample Perceptron on Google Sheets](https://docs.google.com/spreadsheets/d/1gWQugoCEZTMPTZ_LyanFjuPo_GbG-r4-ZRSBLjVPlO0/edit#gid=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC9aASslCnm-"
      },
      "source": [
        "\n",
        "![PN](https://miro.medium.com/max/12840/1*v88ySSMr7JLaIBjwr4chTw.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6URBCTjDjDF"
      },
      "source": [
        "##How does this compare with the Sample NN (Neural Network) from the last class?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0o134K0DsNz"
      },
      "source": [
        "![](https://miro.medium.com/max/1018/1*fW1kWWa1HGosROKkpjzFQw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhRUt60FD5VK"
      },
      "source": [
        "## Sample Perceptron Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lKusYXGnI7l"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSWZ-GK1o1A6"
      },
      "source": [
        "inputs = np.array([[0, 1, 0], # input data (excel column A-C)\n",
        "                   [0, 1, 1],\n",
        "                   [0, 0, 0],\n",
        "                   [1, 0, 0],\n",
        "                   [1, 1, 1],\n",
        "                   [1, 0, 1]])\n",
        "outputs = np.array([[0], [0], [0], [1], [1], [1]]) # output data (Google Sheet column E)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Drnczlm5oh"
      },
      "source": [
        "learning_rate=.01 # Set learning_rate, choose 1 : 1000,100,10,1,0,.01,.001,.0001\n",
        "epochs=4 # Set epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP918X7Sm-r9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01575f60-236c-487a-85b1-05fb4c55b1b6"
      },
      "source": [
        "rand = np.random.RandomState(5) # Random state can be changed\n",
        "weights = rand.normal(loc=0.0, scale=0.01, size=1 +  inputs.shape[1]) # Create initial weights\n",
        "weights # Google Sheet columns G-J"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00441227, -0.0033087 ,  0.02430771, -0.00252092])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhjCmXdwoaFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b351af-aecb-4135-e86f-006450e7d5a9"
      },
      "source": [
        "error_history=[]\n",
        "for _ in range(epochs):\n",
        "  errors_=[]\n",
        "  for input, output in zip(inputs, outputs):\n",
        "    \n",
        "    z = np.dot(input, weights[1:]) + weights[0]\n",
        "    predict = np.where(z >= 0, 1, 0)\n",
        "    \n",
        "    error = output - predict\n",
        "    \n",
        "    update = learning_rate * error\n",
        "    weights[1:] += update * input\n",
        "    weights[0] += update\n",
        "\n",
        "    errors_.append(error)\n",
        "  error_history.append(np.average(np.abs(errors_)))\n",
        "  print(weights)\n",
        "print(error_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.00441227  0.0166913   0.01430771 -0.00252092]\n",
            "[-0.00558773  0.0166913   0.00430771 -0.00252092]\n",
            "[-0.00558773  0.0166913   0.00430771 -0.00252092]\n",
            "[-0.00558773  0.0166913   0.00430771 -0.00252092]\n",
            "[0.6666666666666666, 0.16666666666666666, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzgMvzFOTrua",
        "outputId": "14ea5318-6593-4508-b845-826c076066c0"
      },
      "source": [
        "error_history=[] # Create new error_history\n",
        "for _ in range(epochs): # Loop through epochs\n",
        "  errors_=[] # Create new errors_ list for every epoch\n",
        "  for input, output in zip(inputs, outputs): # Loop through inputs (1 per Google Sheet row in columns A-T)\n",
        "    # Calculate predicted output\n",
        "    z = np.dot(input, weights[1:]) + weights[0] # Calculate z  (Google Sheet column L)\n",
        "    predict = np.where(z >= 0, 1, 0) # Calculate algorithm's prediction (Google Sheet column M)\n",
        "    # Calculate predicted output Error\n",
        "    error = output - predict # Calculate algorithm's error (Google Sheet column N)\n",
        "    # Apply 'learning' and update weights and bias\n",
        "    update = learning_rate * error # Calculate necessary update to weights (Google Sheet column O)\n",
        "    weights[1:] += update * input # Apply update to input weights, one for each input column (Google Sheet columns R-T)\n",
        "    weights[0] += update # Apply update to bias weight (Google Sheet column Q)\n",
        "    # Log the error for error_history below\n",
        "    errors_.append(error) # Create list of errors (Google Sheet column N)\n",
        "  error_history.append(np.average(np.abs(errors_))) # Average list of errors for each epoch (Google Sheet column N, rows 9,18,27,36)\n",
        "  print(weights)\n",
        "print(error_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.00441227  0.0166913   0.01430771 -0.00252092]\n",
            "[-0.00558773  0.0166913   0.00430771 -0.00252092]\n",
            "[-0.00558773  0.0166913   0.00430771 -0.00252092]\n",
            "[-0.00558773  0.0166913   0.00430771 -0.00252092]\n",
            "[0.6666666666666666, 0.16666666666666666, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN8useH0l1mJ"
      },
      "source": [
        "class Perceptron(object):\n",
        "  def __init__(self, learning_rate=0.01, n_iter=100, random_state=1):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.n_iter = n_iter\n",
        "    self.random_state = random_state\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    rand = np.random.RandomState(self.random_state)\n",
        "    self.weights = rand.normal(loc=0.0, scale=0.01, size=1 +  X.shape[1])\n",
        "    self.errors_ = []\n",
        "\n",
        "  for _ in range(self.n_iter):\n",
        "      errors = 0\n",
        "      for x, target in zip(X, y):\n",
        "        update = self.learning_rate * (target - self.predict(x))\n",
        "        self.weights[1:] += update * x\n",
        "        self.weights[0] += update\n",
        "        errors += int(update != 0.0)\n",
        "        self.errors_.append(errors)\n",
        "      return self\n",
        "\n",
        "  def net_input(self, X):\n",
        "    z = np.dot(X, self.weights[1:]) + self.weights[0]\n",
        "    return z\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.where(self.net_input(X) >= 0, 1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}